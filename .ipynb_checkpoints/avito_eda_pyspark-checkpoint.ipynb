{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .master(\"local[*]\")\n",
    "    .config(\"spark.driver.memory\", \"22g\")\n",
    "    .config(\"spark.executor.memory\", \"22g\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = \"C:/BigData/avito-context-ad-clicks/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads_info = spark.read.csv(BASE_PATH+\"AdsInfo.tsv/AdsInfo.tsv\",\n",
    "                        header=True,\n",
    "                        inferSchema=True,\n",
    "                        sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- AdID: integer (nullable = true)\n",
      " |-- LocationID: integer (nullable = true)\n",
      " |-- CategoryID: integer (nullable = true)\n",
      " |-- Params: string (nullable = true)\n",
      " |-- Price: double (nullable = true)\n",
      " |-- Title: string (nullable = true)\n",
      " |-- IsContext: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ads_info.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+----------+--------------------------------------------------+--------+---------------------------------------+---------+\n",
      "|AdID|LocationID|CategoryID|                                            Params|   Price|                                  Title|IsContext|\n",
      "+----+----------+----------+--------------------------------------------------+--------+---------------------------------------+---------+\n",
      "|   1|       343|        43|{1283:'С пробегом', 633:'Синий', 1159:0, 210:'T...|160000.0|                    Toyota Estima, 1993|        0|\n",
      "|   2|       992|        34|{817:'Кузов', 5:'Запчасти', 598:'Для автомобилей'}|   750.0|Передние брызговики Форд Фокус 2 родные|        0|\n",
      "|   3|      3771|        53|                              {181:'Промышленное'}| 18000.0|                               Дровокол|        0|\n",
      "|   4|      4294|        57|                      {130:'Приборы и аксессуары'}|  1500.0|                 Продам ходули складные|        0|\n",
      "|   5|      1344|        34|{817:'Автосвет', 5:'Запчасти', 598:'Для автомоб...|   800.0|          Поворотник R - Carina (20317)|        0|\n",
      "+----+----------+----------+--------------------------------------------------+--------+---------------------------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ads_info.show(5, truncate=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CategoryID: integer (nullable = true)\n",
      " |-- Level: integer (nullable = true)\n",
      " |-- ParentCategoryID: integer (nullable = true)\n",
      " |-- SubcategoryID: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "category = spark.read.csv(BASE_PATH+\"Category.tsv/Category.tsv\",\n",
    "                        header=True,\n",
    "                        inferSchema=True,\n",
    "                        sep=\"\\t\") \n",
    "category.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+----------------+-------------+\n",
      "|CategoryID|Level|ParentCategoryID|SubcategoryID|\n",
      "+----------+-----+----------------+-------------+\n",
      "|         0|    1|              10|           45|\n",
      "|         1|    2|               9|           45|\n",
      "|         2|    3|              12|            5|\n",
      "|         3|    3|               9|           25|\n",
      "|         4|    3|               2|           39|\n",
      "+----------+-----+----------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "category.show(5, truncate=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- LocationID: integer (nullable = true)\n",
      " |-- Level: integer (nullable = true)\n",
      " |-- RegionID: integer (nullable = true)\n",
      " |-- CityID: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "location = spark.read.csv(BASE_PATH+\"Location.tsv/Location.tsv\",\n",
    "                        header=True,\n",
    "                        inferSchema=True,\n",
    "                        sep=\"\\t\") \n",
    "location.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+--------+------+\n",
      "|LocationID|Level|RegionID|CityID|\n",
      "+----------+-----+--------+------+\n",
      "|         7|    3|      83|  2386|\n",
      "|        23|    3|      28|  3224|\n",
      "|        26|    3|      41|  1316|\n",
      "|        30|    3|      63|  2565|\n",
      "|        32|    3|      28|  2819|\n",
      "+----------+-----+--------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "location.show(5, truncate=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- UserID: integer (nullable = true)\n",
      " |-- IPID: integer (nullable = true)\n",
      " |-- AdID: integer (nullable = true)\n",
      " |-- PhoneRequestDate: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "phone_request_stream = spark.read.csv(BASE_PATH+\"PhoneRequestsStream.tsv/PhoneRequestsStream.tsv\",\n",
    "                        header=True,\n",
    "                        inferSchema=True,\n",
    "                        sep=\"\\t\") \n",
    "phone_request_stream.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------+-------------------+\n",
      "| UserID|   IPID|    AdID|   PhoneRequestDate|\n",
      "+-------+-------+--------+-------------------+\n",
      "| 352278|2135799|11720717|2015-04-25 00:00:00|\n",
      "| 392193| 298552|32569552|2015-04-25 00:00:00|\n",
      "| 670687|1426242|22443326|2015-04-25 00:00:00|\n",
      "|1504499| 437051|24774519|2015-04-25 00:00:00|\n",
      "|2648778| 818978|16455042|2015-04-25 00:00:00|\n",
      "+-------+-------+--------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "phone_request_stream.show(5, truncate=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- SearchID: integer (nullable = true)\n",
      " |-- SearchDate: timestamp (nullable = true)\n",
      " |-- IPID: integer (nullable = true)\n",
      " |-- UserID: integer (nullable = true)\n",
      " |-- IsUserLoggedOn: integer (nullable = true)\n",
      " |-- SearchQuery: string (nullable = true)\n",
      " |-- LocationID: integer (nullable = true)\n",
      " |-- CategoryID: integer (nullable = true)\n",
      " |-- SearchParams: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search_info = spark.read.csv(BASE_PATH+\"SearchInfo.tsv/SearchInfo.tsv\",\n",
    "                        header=True,\n",
    "                        inferSchema=True,\n",
    "                        sep=\"\\t\") \n",
    "search_info.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-------+-------+--------------+-----------+----------+----------+-------------------------------------------+\n",
      "|SearchID|         SearchDate|   IPID| UserID|IsUserLoggedOn|SearchQuery|LocationID|CategoryID|                               SearchParams|\n",
      "+--------+-------------------+-------+-------+--------------+-----------+----------+----------+-------------------------------------------+\n",
      "|       1|2015-05-18 19:54:32|1717090|3640266|             0|       NULL|      1729|         5|                                       NULL|\n",
      "|       2|2015-05-12 14:21:28|1731568| 769304|             0|       NULL|       697|        50|                                       NULL|\n",
      "|       3|2015-05-12 07:09:42| 793143| 640089|             0|       NULL|      1261|        12|                                       NULL|\n",
      "|       4|2015-05-10 18:11:01| 898705|3573776|             0|       NULL|      3960|        22|{83:'Обувь', 175:'Женская одежда', 88:'38'}|\n",
      "|       5|2015-04-25 13:04:09|2009707| 320674|             0|       NULL|       547|         1|                                       NULL|\n",
      "+--------+-------------------+-------+-------+--------------+-----------+----------+----------+-------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search_info.show(5, truncate=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- SearchID: integer (nullable = true)\n",
      " |-- AdID: integer (nullable = true)\n",
      " |-- Position: integer (nullable = true)\n",
      " |-- ObjectType: integer (nullable = true)\n",
      " |-- HistCTR: double (nullable = true)\n",
      " |-- IsClick: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_search_stream = spark.read.csv(BASE_PATH+\"trainSearchStream.tsv/trainSearchStream.tsv\",\n",
    "                        header=True,\n",
    "                        inferSchema=True,\n",
    "                        sep=\"\\t\") \n",
    "train_search_stream.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+--------+----------+--------+-------+\n",
      "|SearchID|    AdID|Position|ObjectType| HistCTR|IsClick|\n",
      "+--------+--------+--------+----------+--------+-------+\n",
      "|       2|11441863|       1|         3|0.001804|      0|\n",
      "|       2|22968355|       7|         3|0.004723|      0|\n",
      "|       3|  212187|       7|         3|0.029701|      0|\n",
      "|       3|34084553|       1|         3|  0.0043|      0|\n",
      "|       3|36256251|       2|         2|    NULL|   NULL|\n",
      "+--------+--------+--------+----------+--------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_search_stream.show(5, truncate=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- UserID: integer (nullable = true)\n",
      " |-- UserAgentID: integer (nullable = true)\n",
      " |-- UserAgentOSID: integer (nullable = true)\n",
      " |-- UserDeviceID: integer (nullable = true)\n",
      " |-- UserAgentFamilyID: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_info = spark.read.csv(BASE_PATH+\"UserInfo.tsv/UserInfo.tsv\",\n",
    "                        header=True,\n",
    "                        inferSchema=True,\n",
    "                        sep=\"\\t\") \n",
    "user_info.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+-------------+------------+-----------------+\n",
      "|UserID|UserAgentID|UserAgentOSID|UserDeviceID|UserAgentFamilyID|\n",
      "+------+-----------+-------------+------------+-----------------+\n",
      "|     1|      44073|           30|        2019|                9|\n",
      "|     2|      12505|           20|        2014|               85|\n",
      "|     3|      24256|           20|        2014|               64|\n",
      "|     4|      57133|           20|        2014|               25|\n",
      "|     5|      57133|           20|        2014|               25|\n",
      "+------+-----------+-------------+------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_info.show(5, truncate=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- UserID: integer (nullable = true)\n",
      " |-- IPID: integer (nullable = true)\n",
      " |-- AdID: integer (nullable = true)\n",
      " |-- ViewDate: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "visits_stream = spark.read.csv(BASE_PATH+\"VisitsStream.tsv/VisitsStream.tsv\",\n",
    "                        header=True,\n",
    "                        inferSchema=True,\n",
    "                        sep=\"\\t\")\n",
    "visits_stream.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+--------+-------------------+\n",
      "|UserID|   IPID|    AdID|           ViewDate|\n",
      "+------+-------+--------+-------------------+\n",
      "| 59703|1259356|  469877|2015-04-25 00:00:00|\n",
      "|154389|1846749|27252551|2015-04-25 00:00:00|\n",
      "|218628|2108380|31685325|2015-04-25 00:00:00|\n",
      "|231535| 837110|18827716|2015-04-25 00:00:00|\n",
      "|282306|1654210|29363673|2015-04-25 00:00:00|\n",
      "+------+-------+--------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "visits_stream.show(5, truncate=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stevens",
   "language": "python",
   "name": "stevens"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
